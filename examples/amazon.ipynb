{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wilds import get_dataset\n",
    "from wilds.common.data_loaders import get_train_loader\n",
    "\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "import time\n",
    "import random\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, get_linear_schedule_with_warmup\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = \"/mnt/ssd/ronak/datasets/wilds\"\n",
    "CACHE_DIR = \"/mnt/ssd/ronak/models\"\n",
    "SAVE_DIR = \"/mnt/hdd/ronak/wilds/amazon\"\n",
    "OUT_DIR = \"/mnt/ssd/ronak/output/wilds/amazon\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Dataset\n",
    "\n",
    "Determine the padding length based on the average length of encoded sentences. We then tokenize the dataset and save it to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the full dataset, and download it if necessary\n",
    "dataset = get_dataset(dataset=\"amazon\", download=True, root_dir=ROOT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"timinar/baby-llama-58m\", cache_dir=CACHE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lens(split, n, tokenizer):\n",
    "    # Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "    lens = []\n",
    "\n",
    "    # For every sentence...\n",
    "    # sentences = dataset[split][\"text\"]\n",
    "    # train_data = dataset.get_subset(split)\n",
    "    loader = get_train_loader(\"standard\", dataset.get_subset(split), batch_size=1)\n",
    "    # if split != \"train\":\n",
    "    #     idx = np.arange(len(sentences))\n",
    "    print(f\"Loader size: {len(loader)}.\")\n",
    "    for i, (x, y, z) in tqdm(enumerate(loader)):\n",
    "        encoded_dict = tokenizer(\n",
    "            x[0], \n",
    "            add_special_tokens=True,  # Add '[CLS]' and '[SEP]'\n",
    "            return_tensors=\"pt\", \n",
    "        )\n",
    "\n",
    "        # Add the encoded sentence to the list.\n",
    "        lens.append(encoded_dict[\"input_ids\"].shape[1])\n",
    "\n",
    "        if i == n - 1:\n",
    "            break\n",
    "\n",
    "    return np.array(lens)\n",
    "\n",
    "\n",
    "# generate encoded tokens:\n",
    "def get_split(split, n, tokenizer, max_length=80):\n",
    "    # Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "    input_ids = []\n",
    "    attn_masks = []\n",
    "    labels = []\n",
    "    metadata = []\n",
    "\n",
    "    # For every sentence...\n",
    "    # sentences = dataset[split][\"text\"]\n",
    "    # train_data = dataset.get_subset(split)\n",
    "    loader = get_train_loader(\"standard\", dataset.get_subset(split), batch_size=1)\n",
    "    # if split != \"train\":\n",
    "    #     idx = np.arange(len(sentences))\n",
    "    print(f\"Loader size: {len(loader)}.\")\n",
    "    for i, (x, y, z) in tqdm(enumerate(loader)):\n",
    "        # first encode fully and check length\n",
    "        encoded_dict = tokenizer(\n",
    "            x[0], \n",
    "            add_special_tokens=True,  # Add '[CLS]' and '[SEP]'\n",
    "            return_tensors=\"pt\", \n",
    "        )\n",
    "\n",
    "        # then continue if length is small\n",
    "        if encoded_dict[\"input_ids\"].shape[1] <= max_length:\n",
    "            encoded_dict = tokenizer(\n",
    "                x[0], \n",
    "                add_special_tokens=True,  # Add '[CLS]' and '[SEP]'\n",
    "                max_length=max_length,\n",
    "                truncation=True,\n",
    "                padding='max_length',\n",
    "                return_tensors=\"pt\",  # Return pytorch tensors.return_tensors='pt'\n",
    "                return_attention_mask=True,\n",
    "            )\n",
    "\n",
    "            # Add the encoded sentence to the list.\n",
    "            input_ids.append(encoded_dict[\"input_ids\"])\n",
    "            attn_masks.append(encoded_dict[\"attention_mask\"])\n",
    "            labels.append(y.item())\n",
    "            metadata.append(z)\n",
    "\n",
    "        if len(input_ids) == n - 1:\n",
    "            break\n",
    "\n",
    "    input_ids = torch.cat(input_ids, dim=0)\n",
    "    attn_masks = torch.cat(attn_masks, dim=0)\n",
    "    labels = torch.tensor(labels).long()\n",
    "    metadata = torch.cat(metadata)\n",
    "\n",
    "    return input_ids, attn_masks, labels, metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loader size: 245502.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9999it [00:06, 1604.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n = 10000\n",
    "seq_len = get_lens(\"train\", n, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5 quantile: 129.0\n",
      "0.75 quantile: 254.0\n",
      "0.9 quantile: 393.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for q in [0.5, 0.75, 0.9]:\n",
    "    print(f\"{q} quantile: {np.quantile(seq_len, q)}\")\n",
    "\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "ax.hist(seq_len, bins=20, color=\"tab:blue\", alpha=0.5, edgecolor=\"k\")\n",
    "ax.set_xlabel(\"Tokenized Sequence Length\")\n",
    "ax.set_ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We choose `80` as the sequence length and keep only those examples that are short."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loader size: 245502.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "245502it [03:31, 1160.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([85586, 80])\n",
      "Loader size: 100050.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100050it [01:20, 1235.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([38669, 80])\n",
      "Loader size: 100050.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100050it [01:21, 1227.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([39128, 80])\n"
     ]
    }
   ],
   "source": [
    "n = np.inf\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    input_ids, attn_masks, labels, metadata = get_split(split, n, tokenizer, max_length=80)\n",
    "    \n",
    "    print(input_ids.shape)\n",
    "    torch.save(input_ids, os.path.join(SAVE_DIR, f\"{split}_input_ids.pt\"))\n",
    "    torch.save(attn_masks, os.path.join(SAVE_DIR, f\"{split}_attn_masks.pt\"))\n",
    "    torch.save(labels, os.path.join(SAVE_DIR, f\"{split}_labels.pt\"))\n",
    "    torch.save(metadata, os.path.join(SAVE_DIR, f\"{split}_metadata.pt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model\n",
    "\n",
    "We begin the training procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 2e-5\n",
    "ADAMW_TOLERANCE = 1e-8\n",
    "BATCH_SIZE = 4\n",
    "EPOCHS = 2\n",
    "SEED = 123\n",
    "UNFROZEN = 1\n",
    "device = \"cuda:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at timinar/baby-llama-58m and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LlamaForSequenceClassification(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(16000, 512, padding_idx=0)\n",
       "    (layers): ModuleList(\n",
       "      (0-15): 16 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (k_proj): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (v_proj): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (o_proj): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=512, out_features=1024, bias=False)\n",
       "          (up_proj): Linear(in_features=512, out_features=1024, bias=False)\n",
       "          (down_proj): Linear(in_features=1024, out_features=512, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm()\n",
       "  )\n",
       "  (score): Linear(in_features=512, out_features=5, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## model\n",
    "\n",
    "n_labels = 5\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"timinar/baby-llama-58m\", cache_dir=CACHE_DIR)\n",
    "\n",
    "# model surgery\n",
    "model.score = nn.Linear(in_features=512, out_features=n_labels, bias=False)\n",
    "model.num_labels = n_labels\n",
    "\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "for module in model.model.layers[-UNFROZEN:] + [model.model.norm, model.score]:\n",
    "    for param in module.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Amazon(Dataset):\n",
    "    def __init__(self, input_ids, attn_masks, labels, metadata):\n",
    "        self.input_ids = input_ids\n",
    "        self.attn_masks = attn_masks\n",
    "        self.labels = labels\n",
    "        self.metadata = metadata\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.input_ids[i], self.attn_masks[i], self.labels[i], self.metadata[i]\n",
    "    \n",
    "def load_dataset(split):\n",
    "    input_ids = torch.load(os.path.join(SAVE_DIR, f\"{split}_input_ids.pt\"))\n",
    "    attn_masks = torch.load(os.path.join(SAVE_DIR, f\"{split}_attn_masks.pt\"))\n",
    "    labels = torch.load(os.path.join(SAVE_DIR, f\"{split}_labels.pt\"))\n",
    "    metadata = torch.load(os.path.join(SAVE_DIR, f\"{split}_metadata.pt\"))\n",
    "\n",
    "    return Amazon(input_ids, attn_masks, labels, metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 0.05G\n",
      "85,586 training samples.\n",
      "38,669 validation samples.\n"
     ]
    }
   ],
   "source": [
    "# small enough to fit in CPU memory\n",
    "train_dataset = load_dataset(\"train\")\n",
    "val_dataset = load_dataset(\"val\")\n",
    "\n",
    "a = train_dataset.input_ids\n",
    "print(f\"Train dataset size: {a.element_size() * a.numel() / (1024 ** 3):0.2f}G\")\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, sampler=RandomSampler(train_dataset), batch_size=BATCH_SIZE\n",
    ")\n",
    "print(\"{:>5,} training samples.\".format(len(train_dataset)))\n",
    "validation_dataloader = DataLoader(\n",
    "    val_dataset, sampler=SequentialSampler(val_dataset), batch_size=BATCH_SIZE\n",
    ")\n",
    "print(\"{:>5,} validation samples.\".format(len(val_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01191784 0.02264389 0.08014161 0.26771902 0.61757764]\n",
      "[0.01399054 0.02280897 0.07626264 0.24254571 0.64439215]\n"
     ]
    }
   ],
   "source": [
    "print(np.bincount(train_dataset.labels.numpy()) / len(train_dataset))\n",
    "print(np.bincount(val_dataset.labels.numpy()) / len(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_dataset.metadata[:, 2].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr = LEARNING_RATE, eps = ADAMW_TOLERANCE)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = 0, num_training_steps = EPOCHS * BATCH_SIZE * len(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_dict_of_lists(lst):\n",
    "    return {key: [i[key] for i in lst] for key in lst[0]}\n",
    "\n",
    "def format_time(elapsed):\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "\n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
    "\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed everything.\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "training_stats = []\n",
    "total_t0 = time.time()\n",
    "for epoch_i in range(EPOCHS):\n",
    "\n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"======== Epoch {:} / {:} ========\".format(epoch_i + 1, EPOCHS))\n",
    "    print(\"Training...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "    total_train_loss = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        if step % 200 == 0 and not step == 0:\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            print(\n",
    "                \"  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.\".format(\n",
    "                    step, len(train_dataloader), elapsed\n",
    "                )\n",
    "            )\n",
    "\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        model.zero_grad()\n",
    "\n",
    "        output = model(\n",
    "            input_ids=b_input_ids,\n",
    "            attention_mask=b_input_mask,\n",
    "            labels=b_labels,\n",
    "            return_dict=True,\n",
    "        )\n",
    "\n",
    "        loss = output.loss\n",
    "        logits = output.logits\n",
    "        \n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        # TODO: See if this is needed.\n",
    "        # Clip the norm of the gradients to 1.0.\n",
    "        # This is to help prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "    training_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
    "\n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    total_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "\n",
    "    for batch in validation_dataloader:\n",
    "\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(\n",
    "                input_ids=b_input_ids,\n",
    "                attention_mask=b_input_mask,\n",
    "                labels=b_labels,\n",
    "            )\n",
    "            loss = output.loss\n",
    "            logits = output.logits\n",
    "\n",
    "        total_eval_loss += loss.item()\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to(\"cpu\").numpy()\n",
    "\n",
    "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "\n",
    "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
    "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
    "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "    validation_time = format_time(time.time() - t0)\n",
    "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "    print(\"  Validation took: {:}\".format(validation_time))\n",
    "\n",
    "    training_stats.append(\n",
    "        {\n",
    "            \"epoch\": epoch_i + 1,\n",
    "            \"Training Loss\": avg_train_loss,\n",
    "            \"Valid. Loss\": avg_val_loss,\n",
    "            \"Valid. Accur.\": avg_val_accuracy,\n",
    "            \"Training Time\": training_time,\n",
    "            \"Validation Time\": validation_time,\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")\n",
    "\n",
    "print(\n",
    "    \"Total training took {:} (h:mm:ss)\".format(format_time(time.time() - total_t0))\n",
    ")\n",
    "\n",
    "# Save the model.\n",
    "torch.save(model, os.path.join(OUT_DIR, \"erm.pt\"))\n",
    "training_stats = to_dict_of_lists(training_stats)\n",
    "with open(os.path.join(OUT_DIR, \"erm.json\"), \"w\") as f:\n",
    "    json.dump(training_stats, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Performance\n",
    "\n",
    "We now look at the performance numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
