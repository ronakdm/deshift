{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wilds import get_dataset\n",
    "from wilds.common.data_loaders import get_train_loader\n",
    "\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "import time\n",
    "import random\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import logging\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from transformers import AutoTokenizer, BertForSequenceClassification, get_cosine_schedule_with_warmup\n",
    "from torch.utils.data import DataLoader, RandomSampler, WeightedRandomSampler, SequentialSampler, Dataset\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = \"/mnt/ssd/ronak/datasets/wilds\"\n",
    "CACHE_DIR = \"/mnt/ssd/ronak/models\"\n",
    "SAVE_DIR = \"/mnt/hdd/ronak/wilds/amazon\"\n",
    "OUT_DIR = \"/mnt/ssd/ronak/output/wilds/amazon\"\n",
    "MODEL_NAME = \"bert\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_SIZE = 50000\n",
    "SEQ_LEN = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the full dataset, and download it if necessary\n",
    "dataset = get_dataset(dataset=\"amazon\", download=True, root_dir=ROOT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lens(split, n, tokenizer):\n",
    "    # Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "    lens = []\n",
    "\n",
    "    loader = get_train_loader(\"standard\", dataset.get_subset(split), batch_size=1)\n",
    "    print(f\"Loader size: {len(loader)}.\")\n",
    "    for i, (x, y, z) in tqdm(enumerate(loader)):\n",
    "        encoded_dict = tokenizer(\n",
    "            x[0], \n",
    "            add_special_tokens=True,  # Add '[CLS]' and '[SEP]'\n",
    "            return_tensors=\"pt\", \n",
    "        )\n",
    "\n",
    "        # Add the encoded sentence to the list.\n",
    "        lens.append(encoded_dict[\"input_ids\"].shape[1])\n",
    "\n",
    "        if i == n - 1:\n",
    "            break\n",
    "\n",
    "    return np.array(lens)\n",
    "\n",
    "\n",
    "# generate encoded tokens:\n",
    "def get_split(split, tokenizer, max_length=SEQ_LEN, idx=None):\n",
    "    # Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "    input_ids = []\n",
    "    attn_masks = []\n",
    "    labels = []\n",
    "    metadata = []\n",
    "\n",
    "    # For every sentence...\n",
    "    # sentences = dataset[split][\"text\"]\n",
    "    # train_data = dataset.get_subset(split)\n",
    "    loader = get_train_loader(\"standard\", dataset.get_subset(split), batch_size=1)\n",
    "    print(f\"Loader size: {len(loader)}.\")\n",
    "    for i, (x, y, z) in tqdm(enumerate(loader)):\n",
    "        if idx is None or i in idx:\n",
    "            encoded_dict = tokenizer(\n",
    "                x[0], \n",
    "                add_special_tokens=True,  # Add '[CLS]' and '[SEP]'\n",
    "                max_length=max_length,\n",
    "                truncation=True,\n",
    "                padding='max_length',\n",
    "                return_tensors=\"pt\",  # Return pytorch tensors.return_tensors='pt'\n",
    "                return_attention_mask=True,\n",
    "            )\n",
    "\n",
    "            # Add the encoded sentence to the list.\n",
    "            input_ids.append(encoded_dict[\"input_ids\"])\n",
    "            attn_masks.append(encoded_dict[\"attention_mask\"])\n",
    "            labels.append(y.item())\n",
    "            metadata.append(z)\n",
    "\n",
    "    input_ids = torch.cat(input_ids, dim=0)\n",
    "    attn_masks = torch.cat(attn_masks, dim=0)\n",
    "    labels = torch.tensor(labels).long()\n",
    "    metadata = torch.cat(metadata)\n",
    "\n",
    "    return input_ids, attn_masks, labels, metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loader size: 245502.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2999it [00:01, 1523.49it/s]\n"
     ]
    }
   ],
   "source": [
    "n = 3000\n",
    "seq_len = get_lens(\"train\", n, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5 quantile: 118.0\n",
      "0.75 quantile: 229.25\n",
      "0.9 quantile: 358.0999999999999\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for q in [0.5, 0.75, 0.9]:\n",
    "    print(f\"{q} quantile: {np.quantile(seq_len, q)}\")\n",
    "\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "ax.hist(seq_len, bins=20, color=\"tab:blue\", alpha=0.5, edgecolor=\"k\")\n",
    "ax.set_xlabel(\"Tokenized Sequence Length\")\n",
    "ax.set_ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loader size: 245502.\n",
      "val loader size: 100050.\n",
      "test loader size: 100050.\n"
     ]
    }
   ],
   "source": [
    "# loader sizes\n",
    "sample_sizes = {}\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    loader = get_train_loader(\"standard\", dataset.get_subset(split), batch_size=1)\n",
    "    print(f\"{split} loader size: {len(loader)}.\")\n",
    "    sample_sizes[split] = len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loader size: 245502.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "245502it [01:39, 2460.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50000, 100])\n",
      "Loader size: 100050.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100050it [01:18, 1269.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50000, 100])\n",
      "Loader size: 100050.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100050it [01:18, 1268.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50000, 100])\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(123)\n",
    "\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    idx = np.random.choice(sample_sizes[split], DATA_SIZE, replace=False)\n",
    "    input_ids, attn_masks, labels, metadata = get_split(split, tokenizer, max_length=SEQ_LEN, idx=idx)\n",
    "    \n",
    "    print(input_ids.shape)\n",
    "    torch.save(input_ids, os.path.join(SAVE_DIR, f\"{MODEL_NAME}_{split}_input_ids.pt\"))\n",
    "    torch.save(attn_masks, os.path.join(SAVE_DIR, f\"{MODEL_NAME}_{split}_attn_masks.pt\"))\n",
    "    torch.save(labels, os.path.join(SAVE_DIR, f\"{MODEL_NAME}_{split}_labels.pt\"))\n",
    "    torch.save(metadata, os.path.join(SAVE_DIR, f\"{MODEL_NAME}_{split}_metadata.pt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up Data and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 2e-5\n",
    "ADAMW_TOLERANCE = 1e-8\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 2\n",
    "SEED = 123\n",
    "BALANCE = 0.3 # data scaling\n",
    "OBJECTIVE = \"superquantile\"\n",
    "DEVICE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(split):\n",
    "    input_ids  = torch.load(os.path.join(SAVE_DIR, f\"{MODEL_NAME}_{split}_input_ids.pt\"))\n",
    "    attn_masks = torch.load(os.path.join(SAVE_DIR, f\"{MODEL_NAME}_{split}_attn_masks.pt\"))\n",
    "    labels     = torch.load(os.path.join(SAVE_DIR, f\"{MODEL_NAME}_{split}_labels.pt\"))\n",
    "    metadata   = torch.load(os.path.join(SAVE_DIR, f\"{MODEL_NAME}_{split}_metadata.pt\"))\n",
    "    return input_ids, attn_masks, labels, metadata\n",
    "\n",
    "class MaskedSequenceClassificationDataset(Dataset):\n",
    "    def __init__(self, input_ids, attn_masks, labels, metadata):\n",
    "        self.input_ids = input_ids\n",
    "        self.attn_masks = attn_masks\n",
    "        self.labels = labels\n",
    "        self.metadata = metadata\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.input_ids[i], self.attn_masks[i], self.labels[i], self.metadata[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original label distribution:  [0.0124 0.0261 0.0948 0.2929 0.5738]\n",
      "Rebalanced label distribution: [0.06868 0.07827 0.12636 0.26503 0.46166]\n",
      "10,000 training samples.\n"
     ]
    }
   ],
   "source": [
    "input_ids, attn_masks, labels, metadata = load_data(\"train\")\n",
    "train_dataset = MaskedSequenceClassificationDataset(input_ids, attn_masks, labels, metadata)\n",
    "\n",
    "print(f\"Original label distribution:  {np.bincount(train_dataset.labels.numpy()) / len(train_dataset)}\")\n",
    "\n",
    "label_dist = np.bincount(train_dataset.labels.numpy()) / len(train_dataset)\n",
    "n_labels = len(label_dist)\n",
    "rebalanced_dist = BALANCE * np.ones(shape=(n_labels,)) / n_labels + (1 - BALANCE) * label_dist\n",
    "print(f\"Rebalanced label distribution: {rebalanced_dist}\")\n",
    "# radon-nykodym derivative to go from unbalanced to balanced wieghts\n",
    "rnd = rebalanced_dist / label_dist\n",
    "sample_weight = rnd[train_dataset.labels.numpy()]\n",
    "\n",
    "# use a weighted sampler for upsampling\n",
    "# we can use more data in the forward pass with the same memory budget\n",
    "n_samples = len(sample_weight) if OBJECTIVE == \"erm\" else 2 * len(sample_weight)\n",
    "batch_size = BATCH_SIZE if OBJECTIVE == \"erm\" else 2 * BATCH_SIZE\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, sampler=WeightedRandomSampler(sample_weight, n_samples, replacement=True), batch_size=batch_size, drop_last=True\n",
    ")\n",
    "# train_dataloader = DataLoader(\n",
    "#     train_dataset, sampler=RandomSampler(train_dataset), batch_size=BATCH_SIZE\n",
    "# )\n",
    "print(\"{:>5,} training samples.\".format(len(train_dataset)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training labels:  10000\n",
      "Number of observed labels:  19968\n",
      "Resampled label distribution:  [0.06610577 0.07757412 0.123748   0.26958133 0.46299079]\n"
     ]
    }
   ],
   "source": [
    "# test train_dataloader\n",
    "labels = []\n",
    "for step, batch in enumerate(train_dataloader):\n",
    "    labels.append(batch[2].numpy())\n",
    "labels = np.concatenate(labels)\n",
    "print(f\"Number of training labels:  {len(train_dataset.labels)}\")\n",
    "print(f\"Number of observed labels:  {len(labels)}\")\n",
    "print(f\"Resampled label distribution:  {np.bincount(labels) / len(labels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0131 0.0277 0.0926 0.2827 0.5839]\n",
      "10,000 validation samples.\n",
      "10,000 test samples.\n"
     ]
    }
   ],
   "source": [
    "input_ids, attn_masks, labels, metadata = load_data(\"val\")\n",
    "val_dataset = MaskedSequenceClassificationDataset(input_ids, attn_masks, labels, metadata)\n",
    "print(np.bincount(val_dataset.labels.numpy()) / len(val_dataset))\n",
    "validation_dataloader = DataLoader(\n",
    "    val_dataset, sampler=SequentialSampler(val_dataset), batch_size=BATCH_SIZE\n",
    ")\n",
    "print(\"{:>5,} validation samples.\".format(len(val_dataset)))\n",
    "\n",
    "input_ids, attn_masks, labels, metadata = load_data(\"test\")\n",
    "test_dataset = MaskedSequenceClassificationDataset(input_ids, attn_masks, labels, metadata)\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset, sampler=RandomSampler(test_dataset), batch_size=BATCH_SIZE\n",
    ")\n",
    "print(\"{:>5,} test samples.\".format(len(test_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\",\n",
    "    num_labels=5,\n",
    "    output_attentions=False,\n",
    "    output_hidden_states=False,\n",
    "    cache_dir=CACHE_DIR,\n",
    ").to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr = LEARNING_RATE, eps = ADAMW_TOLERANCE)\n",
    "scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps = 0, num_training_steps = EPOCHS * BATCH_SIZE * len(train_dataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_dict_of_lists(lst):\n",
    "    return {key: [i[key] for i in lst] for key in lst[0]}\n",
    "\n",
    "def format_time(elapsed):\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "\n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
    "\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
    "    handlers=[\n",
    "        logging.FileHandler(os.path.join(OUT_DIR, \"output_{MODEL_NAME}_{OBJECTIVE}.log\")),\n",
    "        logging.FileHandler(\"output_{MODEL_NAME}_{OBJECTIVE}.log\"),\n",
    "        logging.StreamHandler(sys.stdout),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2024-06-01 16:23:59,478 [INFO] ======== Epoch 1 / 2 ========\n",
      "2024-06-01 16:23:59,480 [INFO] Training...\n",
      "2024-06-01 16:24:11,869 [INFO]   Batch    40  of    312.    Elapsed: 0:00:12.   Loss: 1.60212\n",
      "2024-06-01 16:24:23,989 [INFO]   Batch    80  of    312.    Elapsed: 0:00:25.   Loss: 1.54519\n",
      "2024-06-01 16:24:36,189 [INFO]   Batch   120  of    312.    Elapsed: 0:00:37.   Loss: 1.46404\n",
      "2024-06-01 16:24:48,340 [INFO]   Batch   160  of    312.    Elapsed: 0:00:49.   Loss: 1.38631\n",
      "2024-06-01 16:25:00,507 [INFO]   Batch   200  of    312.    Elapsed: 0:01:01.   Loss: 1.33111\n",
      "2024-06-01 16:25:12,699 [INFO]   Batch   240  of    312.    Elapsed: 0:01:13.   Loss: 1.28048\n",
      "2024-06-01 16:25:24,906 [INFO]   Batch   280  of    312.    Elapsed: 0:01:25.   Loss: 1.24271\n",
      "\n",
      "2024-06-01 16:25:34,619 [INFO]   Average training loss:      1.215\n",
      "2024-06-01 16:25:34,620 [INFO]   Average training objective: 1.215\n",
      "2024-06-01 16:25:34,621 [INFO]   Average training accuracy:  0.367\n",
      "2024-06-01 16:25:34,622 [INFO]   Training epoch took:        0:01:35\n",
      "\n",
      "2024-06-01 16:25:34,623 [INFO] Running Validation...\n",
      "2024-06-01 16:25:52,143 [INFO]   Validation Accuracy: 0.649\n",
      "2024-06-01 16:25:52,152 [INFO]               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.31      0.38       131\n",
      "           1       0.31      0.39      0.34       277\n",
      "           2       0.43      0.38      0.40       926\n",
      "           3       0.49      0.37      0.42      2827\n",
      "           4       0.75      0.85      0.79      5839\n",
      "\n",
      "    accuracy                           0.65     10000\n",
      "   macro avg       0.50      0.46      0.47     10000\n",
      "weighted avg       0.63      0.65      0.63     10000\n",
      "\n",
      "2024-06-01 16:25:52,152 [INFO]   Validation Loss: 0.894\n",
      "2024-06-01 16:25:52,153 [INFO]   Validation took: 0:00:18\n",
      "\n",
      "2024-06-01 16:25:52,162 [INFO] ======== Epoch 2 / 2 ========\n",
      "2024-06-01 16:25:52,162 [INFO] Training...\n",
      "2024-06-01 16:26:04,481 [INFO]   Batch    40  of    312.    Elapsed: 0:00:12.   Loss: 0.91577\n",
      "2024-06-01 16:26:16,931 [INFO]   Batch    80  of    312.    Elapsed: 0:00:25.   Loss: 0.88773\n",
      "2024-06-01 16:26:29,483 [INFO]   Batch   120  of    312.    Elapsed: 0:00:37.   Loss: 0.87273\n",
      "2024-06-01 16:26:42,054 [INFO]   Batch   160  of    312.    Elapsed: 0:00:50.   Loss: 0.86502\n",
      "2024-06-01 16:26:54,740 [INFO]   Batch   200  of    312.    Elapsed: 0:01:03.   Loss: 0.84830\n",
      "2024-06-01 16:27:07,421 [INFO]   Batch   240  of    312.    Elapsed: 0:01:15.   Loss: 0.84160\n",
      "2024-06-01 16:27:20,037 [INFO]   Batch   280  of    312.    Elapsed: 0:01:28.   Loss: 0.83110\n",
      "\n",
      "2024-06-01 16:27:30,244 [INFO]   Average training loss:      0.825\n",
      "2024-06-01 16:27:30,245 [INFO]   Average training objective: 0.825\n",
      "2024-06-01 16:27:30,246 [INFO]   Average training accuracy:  0.548\n",
      "2024-06-01 16:27:30,247 [INFO]   Training epoch took:        0:01:38\n",
      "\n",
      "2024-06-01 16:27:30,247 [INFO] Running Validation...\n",
      "2024-06-01 16:27:49,258 [INFO]   Validation Accuracy: 0.655\n",
      "2024-06-01 16:27:49,266 [INFO]               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.36      0.41       131\n",
      "           1       0.36      0.20      0.26       277\n",
      "           2       0.45      0.40      0.42       926\n",
      "           3       0.49      0.32      0.39      2827\n",
      "           4       0.73      0.88      0.80      5839\n",
      "\n",
      "    accuracy                           0.65     10000\n",
      "   macro avg       0.50      0.43      0.46     10000\n",
      "weighted avg       0.62      0.65      0.63     10000\n",
      "\n",
      "2024-06-01 16:27:49,267 [INFO]   Validation Loss: 0.887\n",
      "2024-06-01 16:27:49,268 [INFO]   Validation took: 0:00:19\n",
      "\n",
      "2024-06-01 16:27:49,276 [INFO] Training complete!\n",
      "2024-06-01 16:27:49,277 [INFO] Total training took 0:03:50 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "# Seed everything.\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "training_stats = []\n",
    "total_t0 = time.time()\n",
    "for epoch_i in range(EPOCHS):\n",
    "\n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "\n",
    "    print(\"\")\n",
    "    logging.info(\"======== Epoch {:} / {:} ========\".format(epoch_i + 1, EPOCHS))\n",
    "    logging.info(\"Training...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "    total_train_loss = 0\n",
    "    total_train_objective = 0\n",
    "    total_train_accuracy = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            logging.info(\n",
    "                \"  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.   Loss: {:0.5f}\".format(\n",
    "                    step, len(train_dataloader), elapsed, total_train_loss / step\n",
    "                )\n",
    "            )\n",
    "\n",
    "        b_input_ids = batch[0].to(DEVICE)\n",
    "        b_input_mask = batch[1].to(DEVICE)\n",
    "        b_labels = batch[2].to(DEVICE)\n",
    "\n",
    "        model.zero_grad()\n",
    "\n",
    "        if OBJECTIVE == \"superquantile\":\n",
    "            # use only the examples with high loss.\n",
    "            with torch.no_grad():\n",
    "                output = model(\n",
    "                    input_ids=b_input_ids,\n",
    "                    attention_mask=b_input_mask,\n",
    "                    labels=b_labels,\n",
    "                    return_dict=True,\n",
    "                )\n",
    "                logits = output.logits\n",
    "                losses = F.cross_entropy(logits, b_labels, reduction=\"none\")\n",
    "                sort, argsort = torch.sort(losses, stable=True)\n",
    "                rank = torch.argsort(argsort)\n",
    "        \n",
    "                b_input_ids = b_input_ids[rank >= int(len(losses) / 2)]\n",
    "                b_input_mask = b_input_mask[rank >= int(len(losses) / 2)]\n",
    "                b_labels = b_labels[rank >= int(len(losses) / 2)]\n",
    "\n",
    "        output = model(\n",
    "            input_ids=b_input_ids,\n",
    "            attention_mask=b_input_mask,\n",
    "            labels=b_labels,\n",
    "            return_dict=True,\n",
    "        )\n",
    "\n",
    "        loss = output.loss\n",
    "        logits = output.logits\n",
    "\n",
    "        # sample weighted loss\n",
    "        # losses = F.cross_entropy(logits, b_labels, reduction=\"none\")\n",
    "        # # weights = compute_sample_weight(losses)\n",
    "        # weights = rnd[b_labels] / rnd[b_labels].sum()\n",
    "        # loss = weights @ losses\n",
    "\n",
    "        total_train_loss += output.loss.item()\n",
    "        total_train_objective += loss.item()\n",
    "        loss.backward()\n",
    "        \n",
    "\n",
    "        # TODO: See if this is needed.\n",
    "        # Clip the norm of the gradients to 1.0.\n",
    "        # This is to help prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        total_train_accuracy += flat_accuracy(logits.detach().cpu().numpy(), b_labels.detach().cpu().numpy())\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "    avg_train_objective = total_train_objective / len(train_dataloader)\n",
    "    avg_train_accuracy = total_train_accuracy / len(train_dataloader)\n",
    "    training_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(\"\")\n",
    "    logging.info(\"  Average training loss:      {0:.3f}\".format(avg_train_objective))\n",
    "    logging.info(\"  Average training objective: {0:.3f}\".format(avg_train_objective))\n",
    "    logging.info(\"  Average training accuracy:  {0:.3f}\".format(avg_train_accuracy))\n",
    "    logging.info(\"  Training epoch took:        {:}\".format(training_time))\n",
    "\n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "\n",
    "    print(\"\")\n",
    "    logging.info(\"Running Validation...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    total_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    for batch in validation_dataloader:\n",
    "\n",
    "        b_input_ids = batch[0].to(DEVICE)\n",
    "        b_input_mask = batch[1].to(DEVICE)\n",
    "        b_labels = batch[2].to(DEVICE)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(\n",
    "                input_ids=b_input_ids,\n",
    "                attention_mask=b_input_mask,\n",
    "                labels=b_labels,\n",
    "            )\n",
    "            loss = output.loss\n",
    "            logits = output.logits\n",
    "\n",
    "        total_eval_loss += loss.item()\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to(\"cpu\").numpy()\n",
    "\n",
    "        y_pred.append(np.argmax(logits, axis=1))\n",
    "        y_true.append(label_ids)\n",
    "\n",
    "        # total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "\n",
    "    y_true = np.concatenate(y_true)\n",
    "    y_pred = np.concatenate(y_pred)\n",
    "\n",
    "    avg_val_accuracy = accuracy_score(y_true, y_pred)\n",
    "    logging.info(\"  Validation Accuracy: {0:.3f}\".format(avg_val_accuracy))\n",
    "    logging.info(classification_report(y_true, y_pred, zero_division=0.0))\n",
    "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "    validation_time = format_time(time.time() - t0)\n",
    "    logging.info(\"  Validation Loss: {0:.3f}\".format(avg_val_loss))\n",
    "    logging.info(\"  Validation took: {:}\".format(validation_time))\n",
    "\n",
    "    \n",
    "    epoch_stats = {\n",
    "        \"epoch\": epoch_i + 1,\n",
    "        \"train_loss\": avg_train_loss,\n",
    "        \"train_acc\": avg_train_accuracy,\n",
    "        \"val_loss\": avg_val_loss,\n",
    "        \"val_acc\": avg_val_accuracy,\n",
    "        \"train_time\": training_time,\n",
    "        \"val_time\": validation_time,\n",
    "        \"val_report\": classification_report(y_true, y_pred, zero_division=0.0, output_dict=True)\n",
    "    }\n",
    "    with open(os.path.join(OUT_DIR, f\"{MODEL_NAME}_{OBJECTIVE}_epoch_{epoch_i}.json\"), \"w\") as f:\n",
    "        json.dump(epoch_stats, f, indent=2)\n",
    "    training_stats.append(epoch_stats)\n",
    "\n",
    "print(\"\")\n",
    "logging.info(\"Training complete!\")\n",
    "logging.info(\n",
    "    \"Total training took {:} (h:mm:ss)\".format(format_time(time.time() - total_t0))\n",
    ")\n",
    "\n",
    "# Save the model.\n",
    "torch.save(model.state_dict(), os.path.join(OUT_DIR, f\"{MODEL_NAME}_{OBJECTIVE}.pt\"))\n",
    "training_stats = to_dict_of_lists(training_stats)\n",
    "with open(os.path.join(OUT_DIR, f\"{MODEL_NAME}_{OBJECTIVE}_training_stats.json\"), \"w\") as f:\n",
    "    json.dump(training_stats, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
